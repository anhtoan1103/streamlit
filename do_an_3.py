# -*- coding: utf-8 -*-
"""Do an 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xczcRnHXxzNJHDSdfaAFfUdXZrfch4Pp

*   comment import
*   Gioi71 thieu ve các model

# Đồ án 3 - Fake news detection

Thành viên : 

Đặng Văn Hiển - 18120363

Trà Anh Toàn - 1812662

Lê Thanh Viễn - 18120647

Nguyễn Trần Nhật Minh - 18120208

Nguyễn Vinh Quang - 18120229
"""

# !gdown --id 1W6jrEHY5dhh8PyBAW78S8vj9KTZRoWts
# !gdown --id 1lDmVEf0yWeLJrwtefLlPsi_WylCDDQGw

# !pip install vncorenlp

# !git clone https://github.com/vncorenlp/VnCoreNLP.git

"""# Import"""

import warnings
from sklearn import metrics
import pickle
import time
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import roc_curve
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.decomposition import TruncatedSVD
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import FunctionTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
import re
import seaborn as sns
from vncorenlp import VnCoreNLP
import numpy as np
import pandas as pd
set_config(display='diagram')  # Để trực quan hóa pipeline

warnings.filterwarnings('ignore')

annotator = VnCoreNLP("VnCoreNLP-1.1.1.jar",
                      annotators="wseg,pos,ner,parse", max_heap_size='-Xmx2g')

"""#Tiền xử lý tập dữ liệu

## Đọc file
"""


"""###**Dữ liệu có bao nhiêu dòng và bao nhiêu cột?**"""


"""Vậy tập news_df có 223 dòng và 3 cột

###**Dữ liệu thiếu không ?**
"""


"""Không có dữ liệu thiếu ở các cột

##**Xử lý các dòng**

####**Dữ liệu có các dòng bị lặp không?**
"""


"""Tập news_df có 1 dòng lặp. Ta tiến hành loại bỏ dòng lặp"""


"""####**Mỗi dòng có ý nghĩa gì? Có vấn đề các dòng có ý nghĩa khác nhau không?**

Mỗi dòng cho biết dữ liệu các bài báo và domain name của nó. <br> 
Không có vấn đề các dòng có ý nghĩa khác nhau.

##**Xử lý các cột**

####**Mỗi cột có ý nghĩa gì?**

|Thuộc tính|Kiểu dữ liệu| Ý nghĩa |
|:---:|:---:|:---:|
|text|string|nội dung bài báo|
|domain|string|tên miền bài báo|
|label|boolean|nhãn phân loại tin giả (1) hay thật (0)|

####**Kiểu dữ liệu hiện tại mỗi cột**
"""

"""Kiểu dữ liệu các cột đều phù hợp.

####**Kiểm tra phân bố cột output**
"""


"""Tỉ lệ giữa các giá trị cột output khá cân bằng

####**Tách tập huấn luyện và kiểm thử**
"""


"""#Tiền xử lý ngôn ngữ

# Word Embedding

**N-grams Vectorization**
"""


class PreprocessText(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.pattern = "[^a-z0-9A-Z_ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂưăạảấầẩẫậắằẳẵặẹẻẽềềểỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳỵỷỹ ]*"
        with open("vietnamese-stopwords.txt", encoding="utf-8") as f:
            self.stop_word = f.read().splitlines()
        return

    def fit(self, X_df, y=None):
        return self

    def transform(self, X_df, y=None):
        data = []
        for text in X_df['text']:
            # Chuẩn hoá cột text
            # 1.Loại bỏ ký tự đặc biệt
            text = re.sub(self.pattern, '', text)
            # 2.Tách từ
            text = annotator.tokenize(text)
            # 3.Loại bỏ stop_word
            text = [word for word in text[0] if word not in self.stop_word]
            # 4.Chuẩn hoá chữ thường
            text = [word.lower() for word in text]

            data.append(text)
        return pd.DataFrame({'text': data})


class PreprocessDomain(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.secret = '$'
        return

    def fit(self, X_df, y=None):
        return self

    def transform(self, X_df, y=None):
        data = []
        for domain in X_df['domain']:
            # Chuẩn hoá cột domain
            # 1.Loại bỏ ký tự đặc biệt
            domain = domain.replace('.', ' ')
            # 2.Tách từ
            domain = annotator.tokenize(domain)
            # 3.Chuẩn hoá chữ thường
            domain = [word.lower() for word in domain[0]]
            # 4.Chuẩn hoá chữ thường
            domain = [word + self.secret for word in domain]
            data.append(domain)
        return pd.DataFrame({'domain': data})


class MergeCol(BaseEstimator, TransformerMixin):
    def __init__(self):
        return

    def fit(self, X_df, y=None):
        return self

    def transform(self, X_df, y=None):
        data = []
        for x in X_df:
            data.append(x[0]+x[1])
        return data


"""# Tạo Pipeline

Preprocessor pipeline
"""

colTransformer = ColumnTransformer(transformers=[('text', PreprocessText(), [
                                   'text']), ('domain', PreprocessDomain(), ['domain'])])
preprocessor = make_pipeline(colTransformer, MergeCol())


"""Vectorizer pipeline"""


def dummy(x): return x


vectorizer = make_pipeline(CountVectorizer(
    tokenizer=dummy, lowercase=False), TfidfTransformer())

"""Decomposor pipeline"""

decomposors = {
    'lda': LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=20),
    'tsvd': TruncatedSVD(n_components=int(100), random_state=42),
    '': FunctionTransformer(dummy),
}

decomposor = make_pipeline(decomposors['tsvd'])

"""Model pipeline"""

models = {
    'lgr': LogisticRegression(verbose=1, solver='liblinear', random_state=9, C=5, penalty='l2', max_iter=1000),
    'rfc': RandomForestClassifier(n_estimators=200, max_depth=3, random_state=9),
    'mnb': MultinomialNB(),
    'svc': SVC(C=1.0, kernel='linear', degree=3, gamma='auto'),
}

model = make_pipeline(models['svc'])

"""Full-pipeline"""

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('vectorizer', vectorizer),
    ('decomposor', decomposor),
    ('model', model)
])

pipeline

"""# Huấn luyện mô hình"""

a = {}

a['2'] = 2
a['2'] = 2
a['3'] = 2

score_dict = {}

score_dict

"""#Đánh giá mô hình

## Đánh giá mô hình
"""


"""**Accuracy**"""
